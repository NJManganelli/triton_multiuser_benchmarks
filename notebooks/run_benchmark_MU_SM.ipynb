{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc4a7a1-2167-4ee2-9e79-acc1d10d70e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from distributed import Client\n",
    "from lpcjobqueue import LPCCondorCluster\n",
    "import awkward as ak\n",
    "import numpy as np\n",
    "import torch\n",
    "from utils.mlbench import SimpleWorkLog\n",
    "from utils.mlbench import process_function, create_local_pnmodel, get_triton_client, run_inference_pnmodel, generate_pseudodata_from_seed\n",
    "import time\n",
    "import pathlib\n",
    "#Can use ship_env and the .triton_env with LPCCondorCluster, but here's an alternative that should work for other cluster types\n",
    "from distributed.diagnostics.plugin import UploadDirectory\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2c32d6-158c-4ab7-8764-d3331d8b9298",
   "metadata": {},
   "source": [
    "## Creating a dask cluster\n",
    "A dask cluster can be created, which allows the scale-out of work distributed across multiple networked servers. These servers typically have only CPU resources (no GPU/FPGA co-processors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322e9b8f-a1b9-4b57-b235-78c877f06199",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cluster = LPCCondorCluster(cores=2, \n",
    "                           memory=\"7.5GB\", \n",
    "                           disk=\"4GB\", \n",
    "                           log_directory='/uscmst1b_scratch/lpc1/3DayLifetime/'+str(os.getlogin),\n",
    "                           #ship_env=False,\n",
    "                           #death_timeout=240,\n",
    "                           #schedule_options={\"dashboard_address\": f\":{__get_port():d}\"},\n",
    "                          )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d2bc24-376f-4377-badf-f1f00082c283",
   "metadata": {},
   "source": [
    "The ```adapt``` function can change the requested workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28c42a9-7e10-4021-924b-507d17ec0591",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cluster.adapt(minimum=50, maximum=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f179a1c1-a5f4-477f-ae46-ee79fb08c918",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cluster.workers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02067e3e-2567-4c71-b76a-fadebc724f47",
   "metadata": {},
   "source": [
    "## The client\n",
    "The listed IP address is incorrect for monitoring if we use a tunnel and port-forwarding. Instead, point your browser to \n",
    "https://localhost:8787/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79a33d6-70a6-4587-b2bb-c7abd0e30007",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55cfd377-8e5f-457f-b615-2c7f35e0671c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Uploading directories to access python packages and data\n",
    "The remote workers are not guaranteed to have access to the python packages from this repo. There are multiple mechanisms to rectify this.\n",
    "A general solution for a directory of files is to use the worker plugin ```UploadDirectory```, making sure to update_path and ```restart``` the\n",
    "workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14dfcd7-a133-4e02-b16a-6b40705ba155",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client.register_worker_plugin(UploadDirectory(\"../utils\",restart=True,update_path=True), nanny=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792f0964-91a8-46bd-852a-36b9d9170c43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client.register_worker_plugin(UploadDirectory(\"../models\",restart=True,update_path=True), nanny=True)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec22d583-9a47-41a7-a75b-0430d52c7a11",
   "metadata": {},
   "source": [
    "## Testing client workers\n",
    "To test that all the workers created have access to the packages needed to run the benchmark, we map a function (```test_workers```) to the workers that\n",
    "use try-except clauses to test a few key features, and log the information in the return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37269d9-6e89-4e09-9558-190bba792464",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_structure(x):\n",
    "    \"\"\"Simple test that the uploaded directories are where we expect, and we can import from them\"\"\"\n",
    "    import os\n",
    "    import sys\n",
    "    import pathlib\n",
    "    test = pathlib.Path(\"/srv/utils/\")\n",
    "    success = False\n",
    "    try:\n",
    "        from utils.mlbench import SimpleWorkLog\n",
    "        success = True\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return os.environ, sys.path, success, list(test.iterdir())\n",
    "\n",
    "def test_triton_dask(worker):\n",
    "    \"\"\"Test function for instantiating a triton client on a remote dask worker\"\"\"\n",
    "    x = get_triton_client()\n",
    "    if x is not None:\n",
    "        return \"success\"\n",
    "    else:\n",
    "        return type(x)\n",
    "\n",
    "def print_cluster_info(cluster):\n",
    "    \"\"\"Function for printing some cluster information locally, with some very quick/manual pretty-print formatting\"\"\"\n",
    "    for key in cluster.scheduler_info.keys():\n",
    "        if key not in [\"workers\"]:\n",
    "            print(key, cluster.scheduler_info[key])\n",
    "        else:\n",
    "            print(key)\n",
    "            for address, details in cluster.scheduler_info[key].items():\n",
    "                print(\"\\t\", address)\n",
    "                maxdkey = max([len(dkey) for dkey in details])\n",
    "                for dkey, dval in details.items():\n",
    "                    diff = maxdkey - len(dkey)\n",
    "                    extras = \" \"*diff\n",
    "                    extras += \"  =\\t\"    \n",
    "                    print(\"\\t\\t\", dkey, extras, dval)\n",
    "def test_workers(x):\n",
    "    \"\"\"Fully test the core elements for this benchmark: Being able to identify the client machine (pid/hostname),\n",
    "    import the worklog function, import and run the local and remote model functions\"\"\"\n",
    "    results = {}\n",
    "    try:\n",
    "        import os\n",
    "        results[\"pid\"] = os.getpid()\n",
    "    except:\n",
    "        results[\"pid\"] = False\n",
    "        \n",
    "    import socket\n",
    "    try:\n",
    "        import socket\n",
    "        results[\"hostname\"] = socket.gethostname()\n",
    "    except:\n",
    "        results[\"hostname\"] = False\n",
    "        \n",
    "    try:\n",
    "        from utils.mlbench import SimpleWorkLog\n",
    "        results[\"utils\"] = True\n",
    "    except:\n",
    "        results[\"utils\"] = False\n",
    "        \n",
    "    try:\n",
    "        from utils.mlbench import get_triton_client\n",
    "        _ = get_triton_client()\n",
    "        results[\"triton\"] = True\n",
    "    except:\n",
    "        results[\"triton\"] = False\n",
    "        \n",
    "    try:\n",
    "        from utils.mlbench import create_local_pnmodel\n",
    "        _ = create_local_pnmodel()\n",
    "        results[\"local\"] = True\n",
    "    except:\n",
    "        results[\"local\"] = False\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0b6186-f82f-43a7-9b97-1ec8b500583f",
   "metadata": {},
   "source": [
    "Here is the test of the workers, using the ```gather``` and ```map``` functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe14ea2-8bf9-4e9e-a561-6415dafb0864",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Test the workers can perform basic functions\n",
    "test = client.gather(client.map(test_workers, range(len(cluster.workers))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b3b40a-3138-4271-b13a-bf077720bfd7",
   "metadata": {},
   "source": [
    "We need to know how many unique workers are accessible and ready to distribute work to. If all the numbers match, we have ```n_workers``` ready and able to proceed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6be47b-9118-4bb0-9fb8-c33b83b8d7e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "unique_workers = {}\n",
    "for r in test:\n",
    "    unique_workers[r['hostname']+str(r['pid'])] = r\n",
    "n_workers = len(unique_workers.keys())\n",
    "n_utils_imports = sum([r['utils'] for r in unique_workers.values()])\n",
    "n_triton_functioning = sum([r['triton'] for r in unique_workers.values()])\n",
    "n_local_functioning = sum([r['local'] for r in unique_workers.values()])\n",
    "n_workers, n_utils_imports, n_triton_functioning, n_local_functioning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b636686-f3d6-4ba7-89e8-b36bfbd7c8d6",
   "metadata": {},
   "source": [
    "## Creating work parcels\n",
    "Here we create work parcels to map to the ```process_function``` defined in ```utils.mlbench```\n",
    "\n",
    "For triton inference, we have ```workargstriton``` and ```workargstritonlong```, the latter of which is designed to run 10 times as long. ```workargslocal``` is for local CPU inference, and will perform a factor of ~50x slower than the triton inference.\n",
    "Each sublist is (in this order) the seed for random number generation, the number of pseudo-events to create, the batchsize for inference (limited memory requiring smaller batches on CPU-only workers), and finally whether the inference should proceed via Triton or not.\n",
    "When the ```client.map``` function is called, the first parcel will take the first argument from each of these 4 sublists, and the last from the last argument of each sublist. ```client.submit``` can also be used to distribute the work parcels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03499eb7-cf02-49d4-905d-0e662f3e0e55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_workers = 100\n",
    "long_multiplier = 10\n",
    "#seeds, #pseudo-events, batchsize, use triton (True/False)\n",
    "workargstriton = [range(n_workers), [1000]*n_workers, [1000]*n_workers, [True]*n_workers]\n",
    "workargslocal = [range(n_workers), [1000]*n_workers, [250]*n_workers, [False]*n_workers]\n",
    "workargstritonlong =  [range(n_workers*long_multiplier), \n",
    "                      [9999]*n_workers*long_multiplier, \n",
    "                      [1000]*n_workers*long_multiplier, \n",
    "                      [True]*n_workers*long_multiplier]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41dab08f-7eb8-4dde-b3f6-904d4cd8d8c1",
   "metadata": {},
   "source": [
    "## Test\n",
    "Here we test the ```run_inference_pnmodel``` function, which is one of the core steps of ```process_function```.\n",
    "This will take an input of (pseudo)data, a local ParticleNet model or triton client configured for the same model, as well as a worklog function which will collect some dask client metrics like time spent in the various functions, the hostname, the number of bytes sent over the network for inferences, and so on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bae7f94-a3d8-4588-87e6-eb77dd1a662e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with_outputs, inf_worklogs, errors = run_inference_pnmodel(\n",
    "    generate_pseudodata_from_seed(983, 1000), \n",
    "    get_triton_client(), \n",
    "    batchsize=1000, \n",
    "    triton=True, \n",
    "    worklog=SimpleWorkLog\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cad5a0c-bc90-4453-a836-230c5e53676a",
   "metadata": {},
   "source": [
    "## Test Triton workers\n",
    "For 100 work parcels of 1000 pseudoevents, this can run in a few minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97852189-d1e9-47c1-b954-2643c1a92ce7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Triton, N workers trial\n",
    "print(\"time\", time.time())\n",
    "pft = time.perf_counter()\n",
    "futurestriton = client.map(process_function, *workargstriton, pure=False)\n",
    "resulttriton = client.gather(futurestriton)\n",
    "print(\"runtime(s)\", time.perf_counter() - pft)\n",
    "print(\"time\", time.time())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243fd6b9-f3f2-4330-a1a2-f5054dca5fd8",
   "metadata": {},
   "source": [
    "### Save the worklogs which are returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57f5fcc-99d3-48d0-abd1-4482d5547be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"wm_triton_benchmark00.pickle\", \"wb\") as output_file:\n",
    "    pickle.dump(resulttriton, output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf43b28-1406-40af-9885-36ac4c668634",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Stress Test Triton workers\n",
    "This function should take 10 times as long, roughly, if the inference calls are the majority of the processing time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10ab7ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Triton, N workers trial long\n",
    "print(\"time\", time.time())\n",
    "pft = time.perf_counter()\n",
    "futurestlong = client.map(process_function, *workargstritonlong, pure=False)\n",
    "resulttlong = client.gather(futurestlong)\n",
    "print(\"runtime(s)\", time.perf_counter() - pft)\n",
    "print(\"time\", time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a1000c-f701-4333-b019-054e4a7abea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"wm_tritonlong_benchmark00.pickle\", \"wb\") as output_file:\n",
    "    pickle.dump(resulttlong, output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b08701e-8259-474c-8578-761ea19e7aa7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Test Local workers\n",
    "This requests the analogue of the ```Test Triton workers``` cell, but uses each dask worker's local CPU to run inference. \n",
    "This can take 50x longer to run, so the number of generated events and work parcels should be carefully balanced "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce99067-75c5-4bf2-8935-5621356fbdd8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Local, N workers trial\n",
    "print(\"time\", time.time())\n",
    "pfl = time.perf_counter()\n",
    "futureslocal = client.map(process_function, *workargslocal, pure=False)\n",
    "resultlocal = client.gather(futureslocal)\n",
    "print(\"runtime(s)\", time.perf_counter() - pfl)\n",
    "print(\"time\", time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4d7ab0-610f-4462-a746-4dacdd9b0286",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"wm_local_benchmark00.pickle\", \"wb\") as output_file:\n",
    "    pickle.dump(resultlocal, output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c441d3-c7a8-490e-b2ed-0c707c4d2012",
   "metadata": {},
   "source": [
    "## Close the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6e0095-faa4-4579-8e9a-d4ea8f75cb2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cluster.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coffea for triton",
   "language": "python",
   "name": "coffea-triton"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
